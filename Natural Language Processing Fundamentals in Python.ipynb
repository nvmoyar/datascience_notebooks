{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Natural Language Processing Fundamentals in Python\n",
    "\n",
    " \n",
    "NLP is focused in making sense of human language using computers and statistics. Comon uses are topic identification and text classification.  \n",
    "\n",
    "NLP Applications: \n",
    "\n",
    "* Sentiment analysis\n",
    "* Chatbot \n",
    "* Automatic translations\n",
    "\n",
    "## Regular expressions & word tokenization\n",
    "\n",
    "A regular expression (regex or regexp for short) is a special text string for describing a search pattern. You\n",
    "can think of regular expressions as wildcards on steroids. You are probably familiar with wildcard notations\n",
    "such as *.txt to find all text files in a file manager. The regex equivalent is Â«.*\\.txtÂ».[1](https://www.princeton.edu/~mlovett/reference/Regular-Expressions.pdf)\n",
    "\n",
    "### Common patterns\n",
    "\n",
    "|    Pattern      |               Matches                           |    Example        |\n",
    "|:---------------:|:-----------------------------------------------:|:-----------------:|\n",
    "|   \\w+           |                word                             |    'Magic'        |  \n",
    "|   \\d            |                digit                            |       9           | \n",
    "|   \\s            |               spaces                            |      ' '          | \n",
    "|   .*            |              wildcard                           |  'username74'     | \n",
    "| + or *\t      |            greedy match                         |\t   'aaaaaa'     |\n",
    "|   \\S\t          |             not space                           |\t  'no_spaces'   |\n",
    "|  [a-z]\t      |             lowercase                           |    'abcdefg'      |\n",
    "|[A-Za-z]+\t      | upper and lowercase English alphabet\t        |   'ABCDEFghijk'   |\n",
    "|[0-9]\t          |   numbers from 0 to 9\t                        |          9        |\n",
    "|[A-Za-z\\-\\.]+\t  |  upper and lowercase English alphabet, - and .  | 'My-Website.com'  |\n",
    "|   (a-z)\t      |              a, - and z\t                        |        'a-z'      |\n",
    "|  (\\s+l,)        |\t       spaces or a comma\t                    |         ', '      |\n",
    "\n",
    "### How to do it with Python? \n",
    "\n",
    "* re module\n",
    "* split: split a string on regex\n",
    "* findall: find all patterns in a string\n",
    "* search: search for a pattern\n",
    "* match: match an entire string or substring based on a pattern\n",
    "* Define pattern first, and the string second\n",
    "> Depending on the method used, it may return an iterator, string, or match object\n",
    "\n",
    "### Which pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Let', 's', 'write', 'RegEx']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "my_string = \"Let's write RegEx!\"\n",
    "re.findall(r\"\\w+\", my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Practicing regular expressions: re.split() and re.findall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_string = \"Let's write RegEx!  Won't that be fun?  I sure think so.  Can you find 4 sentences?  Or perhaps, all 19 words?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's write RegEx\", \"  Won't that be fun\", '  I sure think so', '  Can you find 4 sentences', '  Or perhaps, all 19 words', '']\n",
      "['Let', 'RegEx', 'Won', 'Can', 'Or']\n",
      "[\"Let's\", 'write', 'RegEx!', \"Won't\", 'that', 'be', 'fun?', 'I', 'sure', 'think', 'so.', 'Can', 'you', 'find', '4', 'sentences?', 'Or', 'perhaps,', 'all', '19', 'words?']\n",
      "['4', '19']\n"
     ]
    }
   ],
   "source": [
    "# Import the regex module\n",
    "import re\n",
    "\n",
    "# Write a pattern to match sentence endings: sentence_endings\n",
    "sentence_endings = r\"[.?!]\"\n",
    "\n",
    "# Split my_string on sentence endings and print the result\n",
    "print(re.split(sentence_endings, my_string))\n",
    "\n",
    "# Find all capitalized words in my_string and print the result\n",
    "capitalized_words = r\"[A-Z]\\w+\"\n",
    "print(re.findall(capitalized_words, my_string))\n",
    "\n",
    "# Split my_string on spaces and print the result\n",
    "spaces = r\"\\s+\"\n",
    "print(re.split(spaces, my_string))\n",
    "\n",
    "# Find all digits in my_string and print the result\n",
    "digits = r\"\\d+\"\n",
    "print(re.findall(digits, my_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess NLP: Tokenization\n",
    "\n",
    "Turning a string or document into tokens (smaller chunks). There are many different theories and rules and you can create your own rules using regular expressions for: \n",
    "\n",
    "* Breaking out words or sentences\n",
    "* Separating punctuation\n",
    "* Separating all hashtags in a tweet\n",
    "\n",
    "### Why tokenize? \n",
    "\n",
    "* Easier to map part of speech: words like 'awesome' or 'aweful' for Sentiment analysis\n",
    "* Matching common words\n",
    "* Removing unwanted tokens like articles: 'the', 'and', etc.\n",
    "\n",
    "### How? \n",
    "\n",
    "* nltk library\n",
    "* sent_tokenize: tokenize a document into sentences\n",
    "* regexp_tokenize: tokenize a string or document based on a regular expression pattern\n",
    "* TweetTokenizer: special class just for tweet tokenization, allowing you to separate hashtags, mentions and lots of exclamation points!!!\n",
    "* ** Careful to difference between re.search() and re.match()** : match() searches a pattern from the beginning until it cannot match any longer. Search() will go through the entire string searching for the pattern. \n",
    "\n",
    "### Word tokenization with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /anaconda/envs/aind_clone1/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six in /anaconda/envs/aind_clone1/lib/python3.6/site-packages (from nltk)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!  [clop clop clop] \\nSOLDIER #1: Halt!  Who goes there?\\nARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!\\nSOLDIER #1: Pull the other one!\\nARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.\\nSOLDIER #1: What?  Ridden on a horse?\\nARTHUR: Yes!\\nSOLDIER #1: You're using coconuts!\\nARTHUR: What?\\nSOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\\nARTHUR: So?  We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\\nARTHUR: We found them.\\nSOLDIER #1: Found them?  In Mercea?  The coconut's tropical!\\nARTHUR: What do you mean?\\nSOLDIER #1: Well, this is a temperate zone.\\nARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?\\nSOLDIER #1: Are you suggesting coconuts migrate?\\nARTHUR: Not at all.  They could be carried.\\nSOLDIER #1: What?  A swallow carrying a coconut?\\nARTHUR: It could grip it by the husk!\\nSOLDIER #1: It's not a question of where he grips it!  It's a simple question of weight ratios!  A five ounce bird could not carry a one pound coconut.\\nARTHUR: Well, it doesn't matter.  Will you go and tell your master that Arthur from the Court of Camelot is here.\\nSOLDIER #1: Listen.  In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?\\nARTHUR: Please!\\nSOLDIER #1: Am I right?\\nARTHUR: I'm not interested!\\nSOLDIER #2: It could be carried by an African swallow!\\nSOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.  That's my point.\\nSOLDIER #2: Oh, yeah, I agree with that.\\nARTHUR: Will you ask your master if he wants to join my court at Camelot?!\\nSOLDIER #1: But then of course a-- African swallows are non-migratory.\\nSOLDIER #2: Oh, yeah...\\nSOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!  Supposing two swallows carried it together?\\nSOLDIER #1: No, they'd have to have it on a line.\\nSOLDIER #2: Well, simple!  They'd just use a strand of creeper!\\nSOLDIER #1: What, held under the dorsal guiding feathers?\\nSOLDIER #2: Well, why not?\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_one = \"SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!  [clop clop clop] \\nSOLDIER #1: Halt!  Who goes there?\\nARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!\\nSOLDIER #1: Pull the other one!\\nARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.\\nSOLDIER #1: What?  Ridden on a horse?\\nARTHUR: Yes!\\nSOLDIER #1: You're using coconuts!\\nARTHUR: What?\\nSOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\\nARTHUR: So?  We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\\nARTHUR: We found them.\\nSOLDIER #1: Found them?  In Mercea?  The coconut's tropical!\\nARTHUR: What do you mean?\\nSOLDIER #1: Well, this is a temperate zone.\\nARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?\\nSOLDIER #1: Are you suggesting coconuts migrate?\\nARTHUR: Not at all.  They could be carried.\\nSOLDIER #1: What?  A swallow carrying a coconut?\\nARTHUR: It could grip it by the husk!\\nSOLDIER #1: It's not a question of where he grips it!  It's a simple question of weight ratios!  A five ounce bird could not carry a one pound coconut.\\nARTHUR: Well, it doesn't matter.  Will you go and tell your master that Arthur from the Court of Camelot is here.\\nSOLDIER #1: Listen.  In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?\\nARTHUR: Please!\\nSOLDIER #1: Am I right?\\nARTHUR: I'm not interested!\\nSOLDIER #2: It could be carried by an African swallow!\\nSOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.  That's my point.\\nSOLDIER #2: Oh, yeah, I agree with that.\\nARTHUR: Will you ask your master if he wants to join my court at Camelot?!\\nSOLDIER #1: But then of course a-- African swallows are non-migratory.\\nSOLDIER #2: Oh, yeah...\\nSOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!  Supposing two swallows carried it together?\\nSOLDIER #1: No, they'd have to have it on a line.\\nSOLDIER #2: Well, simple!  They'd just use a strand of creeper!\\nSOLDIER #1: What, held under the dorsal guiding feathers?\\nSOLDIER #2: Well, why not?\\n\"\n",
    "scene_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!',\n",
       " '[clop clop clop] \\nSOLDIER #1: Halt!',\n",
       " 'Who goes there?',\n",
       " 'ARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.',\n",
       " 'King of the Britons, defeator of the Saxons, sovereign of all England!',\n",
       " 'SOLDIER #1: Pull the other one!',\n",
       " 'ARTHUR: I am, ...  and this is my trusty servant Patsy.',\n",
       " 'We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.',\n",
       " 'I must speak with your lord and master.',\n",
       " 'SOLDIER #1: What?',\n",
       " 'Ridden on a horse?',\n",
       " 'ARTHUR: Yes!',\n",
       " \"SOLDIER #1: You're using coconuts!\",\n",
       " 'ARTHUR: What?',\n",
       " \"SOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\",\n",
       " 'ARTHUR: So?',\n",
       " \"We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\",\n",
       " 'ARTHUR: We found them.',\n",
       " 'SOLDIER #1: Found them?',\n",
       " 'In Mercea?',\n",
       " \"The coconut's tropical!\",\n",
       " 'ARTHUR: What do you mean?',\n",
       " 'SOLDIER #1: Well, this is a temperate zone.',\n",
       " 'ARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?',\n",
       " 'SOLDIER #1: Are you suggesting coconuts migrate?',\n",
       " 'ARTHUR: Not at all.',\n",
       " 'They could be carried.',\n",
       " 'SOLDIER #1: What?',\n",
       " 'A swallow carrying a coconut?',\n",
       " 'ARTHUR: It could grip it by the husk!',\n",
       " \"SOLDIER #1: It's not a question of where he grips it!\",\n",
       " \"It's a simple question of weight ratios!\",\n",
       " 'A five ounce bird could not carry a one pound coconut.',\n",
       " \"ARTHUR: Well, it doesn't matter.\",\n",
       " 'Will you go and tell your master that Arthur from the Court of Camelot is here.',\n",
       " 'SOLDIER #1: Listen.',\n",
       " 'In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?',\n",
       " 'ARTHUR: Please!',\n",
       " 'SOLDIER #1: Am I right?',\n",
       " \"ARTHUR: I'm not interested!\",\n",
       " 'SOLDIER #2: It could be carried by an African swallow!',\n",
       " 'SOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.',\n",
       " \"That's my point.\",\n",
       " 'SOLDIER #2: Oh, yeah, I agree with that.',\n",
       " 'ARTHUR: Will you ask your master if he wants to join my court at Camelot?!',\n",
       " 'SOLDIER #1: But then of course a-- African swallows are non-migratory.',\n",
       " 'SOLDIER #2: Oh, yeah...',\n",
       " \"SOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!\",\n",
       " 'Supposing two swallows carried it together?',\n",
       " \"SOLDIER #1: No, they'd have to have it on a line.\",\n",
       " 'SOLDIER #2: Well, simple!',\n",
       " \"They'd just use a strand of creeper!\",\n",
       " 'SOLDIER #1: What, held under the dorsal guiding feathers?',\n",
       " 'SOLDIER #2: Well, why not?']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split scene_one into sentences: sentences\n",
    "sentences = sent_tokenize(scene_one)\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARTHUR',\n",
       " ':',\n",
       " 'It',\n",
       " 'is',\n",
       " 'I',\n",
       " ',',\n",
       " 'Arthur',\n",
       " ',',\n",
       " 'son',\n",
       " 'of',\n",
       " 'Uther',\n",
       " 'Pendragon',\n",
       " ',',\n",
       " 'from',\n",
       " 'the',\n",
       " 'castle',\n",
       " 'of',\n",
       " 'Camelot',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use word_tokenize to tokenize the fourth sentence: tokenized_sent\n",
    "tokenized_sent = word_tokenize(sentences[3])\n",
    "\n",
    "tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '#',\n",
       " \"'\",\n",
       " \"'d\",\n",
       " \"'em\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " ',',\n",
       " '--',\n",
       " '.',\n",
       " '...',\n",
       " '1',\n",
       " '2',\n",
       " ':',\n",
       " '?',\n",
       " 'A',\n",
       " 'ARTHUR',\n",
       " 'African',\n",
       " 'Am',\n",
       " 'Are',\n",
       " 'Arthur',\n",
       " 'Britons',\n",
       " 'But',\n",
       " 'Camelot',\n",
       " 'Court',\n",
       " 'England',\n",
       " 'European',\n",
       " 'Found',\n",
       " 'Halt',\n",
       " 'I',\n",
       " 'In',\n",
       " 'It',\n",
       " 'KING',\n",
       " 'King',\n",
       " 'Listen',\n",
       " 'Mercea',\n",
       " 'No',\n",
       " 'Not',\n",
       " 'Oh',\n",
       " 'Patsy',\n",
       " 'Pendragon',\n",
       " 'Please',\n",
       " 'Pull',\n",
       " 'Ridden',\n",
       " 'SCENE',\n",
       " 'SOLDIER',\n",
       " 'Saxons',\n",
       " 'So',\n",
       " 'Supposing',\n",
       " 'That',\n",
       " 'The',\n",
       " 'They',\n",
       " 'Uther',\n",
       " 'Wait',\n",
       " 'We',\n",
       " 'Well',\n",
       " 'What',\n",
       " 'Where',\n",
       " 'Who',\n",
       " 'Whoa',\n",
       " 'Will',\n",
       " 'Yes',\n",
       " 'You',\n",
       " '[',\n",
       " ']',\n",
       " 'a',\n",
       " 'agree',\n",
       " 'air-speed',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'anyway',\n",
       " 'are',\n",
       " 'ask',\n",
       " 'at',\n",
       " 'back',\n",
       " 'bangin',\n",
       " 'be',\n",
       " 'beat',\n",
       " 'bird',\n",
       " 'breadth',\n",
       " 'bring',\n",
       " 'but',\n",
       " 'by',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'castle',\n",
       " 'climes',\n",
       " 'clop',\n",
       " 'coconut',\n",
       " 'coconuts',\n",
       " 'could',\n",
       " 'course',\n",
       " 'court',\n",
       " 'covered',\n",
       " 'creeper',\n",
       " 'defeator',\n",
       " 'do',\n",
       " 'does',\n",
       " 'dorsal',\n",
       " 'empty',\n",
       " 'every',\n",
       " 'feathers',\n",
       " 'five',\n",
       " 'fly',\n",
       " 'forty-three',\n",
       " 'found',\n",
       " 'from',\n",
       " 'get',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'got',\n",
       " 'grip',\n",
       " 'grips',\n",
       " 'guiding',\n",
       " 'halves',\n",
       " 'have',\n",
       " 'he',\n",
       " 'held',\n",
       " 'here',\n",
       " 'horse',\n",
       " 'house',\n",
       " 'husk',\n",
       " 'if',\n",
       " 'in',\n",
       " 'interested',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'join',\n",
       " 'just',\n",
       " 'kingdom',\n",
       " 'knights',\n",
       " 'land',\n",
       " 'length',\n",
       " 'line',\n",
       " 'lord',\n",
       " 'maintain',\n",
       " 'martin',\n",
       " 'master',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'migrate',\n",
       " 'minute',\n",
       " 'must',\n",
       " 'my',\n",
       " \"n't\",\n",
       " 'needs',\n",
       " 'non-migratory',\n",
       " 'not',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'or',\n",
       " 'order',\n",
       " 'other',\n",
       " 'ounce',\n",
       " 'our',\n",
       " 'plover',\n",
       " 'point',\n",
       " 'pound',\n",
       " 'question',\n",
       " 'ratios',\n",
       " 'ridden',\n",
       " 'right',\n",
       " 'search',\n",
       " 'second',\n",
       " 'seek',\n",
       " 'servant',\n",
       " 'simple',\n",
       " 'since',\n",
       " 'snows',\n",
       " 'son',\n",
       " 'south',\n",
       " 'sovereign',\n",
       " 'speak',\n",
       " 'strand',\n",
       " 'strangers',\n",
       " 'suggesting',\n",
       " 'sun',\n",
       " 'swallow',\n",
       " 'swallows',\n",
       " 'tell',\n",
       " 'temperate',\n",
       " 'that',\n",
       " 'the',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'through',\n",
       " 'times',\n",
       " 'to',\n",
       " 'together',\n",
       " 'tropical',\n",
       " 'trusty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'use',\n",
       " 'using',\n",
       " 'velocity',\n",
       " 'wants',\n",
       " 'warmer',\n",
       " 'weight',\n",
       " 'where',\n",
       " 'who',\n",
       " 'why',\n",
       " 'will',\n",
       " 'wind',\n",
       " 'wings',\n",
       " 'winter',\n",
       " 'with',\n",
       " 'yeah',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'zone'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of unique tokens in the entire scene: unique_tokens\n",
    "unique_tokens = set(word_tokenize(scene_one))\n",
    "\n",
    "unique_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### More regex with re.search()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580 588\n"
     ]
    }
   ],
   "source": [
    "# Search for the first occurrence of \"coconuts\" in scene_one: match\n",
    "match = re.search(\"coconuts\", scene_one)\n",
    "\n",
    "# Print the start and end indexes of match\n",
    "print(match.start(), match.end())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(9, 32), match='[wind] [clop clop clop]'>\n",
      "<_sre.SRE_Match object; span=(0, 6), match='ARTHUR'>\n"
     ]
    }
   ],
   "source": [
    "# Write a regular expression to search for anything in square brackets: pattern1\n",
    "pattern1 = r\"\\[.*\\]\"\n",
    "\n",
    "# Use re.search to find the first text in square brackets\n",
    "print(re.search(pattern1, scene_one))\n",
    "\n",
    "# Find the script notation at the beginning of the fourth sentence and print it\n",
    "pattern2 = r\"[A-Z]\\w+\"\n",
    "print(re.match(pattern2, sentences[3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Choosing a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns = [r\"\\w+(\\?!)\", r\"(\\w+|#\\d|\\?|!)\", r\"(#\\d\\w+\\?!)\", r\"\\s+\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['SOLDIER', '#1', 'Found', 'them', '?', 'In', 'Mercea', '?', 'The', 'coconut', 's', 'tropical', '!']\n",
      "[]\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(patterns)): \n",
    "    print(regexp_tokenize(my_string, patterns[i]))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex with NLTK tokenization\n",
    "\n",
    "Twitter is a frequently used source for NLP text and tasks. In this exercise, you'll build a more complex tokenizer for tweets with hashtags and mentions using nltk and regex. The nltk.tokenize.TweetTokenizer class gives you some extra methods and attributes for parsing tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = ['This is the best #nlp exercise ive found online! #python', '#NLP is super fun! <3 #learning', 'Thanks @datacamp :) #nlp #python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This', 'is', 'the', 'best', '#nlp', 'exercise', 'ive', 'found', 'online', '!', '#python'], ['#NLP', 'is', 'super', 'fun', '!', '<3', '#learning'], ['Thanks', '@datacamp', ':)', '#nlp', '#python']]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Define a regex pattern to find hashtags: pattern1\n",
    "pattern1 = r\"#\\w+\"\n",
    "\n",
    "# Use the pattern on the first tweet in the tweets list\n",
    "regexp_tokenize(tweets[0], pattern1)\n",
    "\n",
    "# Write a pattern that matches both mentions and hashtags\n",
    "pattern2 = r\"([#|@]\\w+)\"\n",
    "\n",
    "# Use the pattern on the last tweet in the tweets list\n",
    "regexp_tokenize(tweets[-1], pattern2)\n",
    "\n",
    "# Use the TweetTokenizer to tokenize all tweets into one list\n",
    "tknzr = TweetTokenizer()\n",
    "all_tokens = [tknzr.tokenize(t) for t in tweets]\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-ascii tokenization\n",
    "\n",
    "In this exercise, you'll practice advanced tokenization by tokenizing some non-ascii based text. You'll be using German with emoji!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "german_text = \"Wann gehen wir zum Pizza? ðŸ• Und fÃ¤hrst du mit Ãœber? ðŸš•\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
